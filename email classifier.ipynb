import pandas as pd
import os
import re
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

ham = read_ham()
spam = read_spam()

df = pd.DataFrame.from_records(ham)
df = df.append(pd.DataFrame.from_records(spam))

def read_spam():
    category = 'spam'
    directory = './enron1/spam'
    return read_category(category, directory)

def read_ham():
    category = 'ham'
    directory = './enron1/ham'
    return read_category(category, directory)

def read_category(category, directory):
    emails = []
    for filename in os.listdir(directory):
        if not filename.endswith(".txt"):
            continue
        with open(os.path.join(directory, filename), 'r') as fp:
            try:
                content = fp.read()
                emails.append({'name': filename, 'content': content, 'category': category})
            except:
                print(f'skipped {filename}')
    return emails

def preprocessor(input_string):
    processed_string = ''.join(e for e in input_string if e.isalpha()).lower()
    return processed_string

def preprocessor(input_string):
    processed_string = ''.join(e for e in input_string if e.isalpha()).lower()
    return processed_string

vectorizer = CountVectorizer(tokenizer=preprocessor)
text_samples = [
    "This is a sample text!",
    "Another sample text, with different words.",
    "And another text, with even more different words."
]
vectors = vectorizer.fit_transform(text_samples)
print(vectors)

X = [spam, ham]
y = ['spam', 'ham']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vectors = vectorizer.fit_transform(ham, spam)

model = LogisticRegression()
model.fit(X_train, y_train)

X_test_transformed = vectorizer.transform(X_test)
predictions = model.predict(X_test_transformed)
print(predictions)

predictions = model.predict(X_test_transformed)
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)
confusion = confusion_matrix(y_test, predictions)
print("Confusion matrix:\n", confusion)
report = classification_report(y_test, predictions)
print("Classification report:\n", report)

X_train_transformed = vectorizer.transform(X_train)
feature_names = vectorizer.get_feature_names_out()
df = pd.DataFrame(data=feature_names, columns=["Features"])
print(df)

coefficients = model.coef_[0]
print("Coefficients:", coefficients)
print("\nIn the context of logistic regression, the coefficients represent the change in the log odds of the positive class")
print("(e.g., spam) for a one-unit increase in the corresponding feature (word). In other words, the coefficients indicate")
print("how much the log odds of a document being spam increases or decreases for each occurrence of a particular word.")
print("\nThe most important words for predicting spam emails are:")
for i, word in enumerate(vectorizer.get_feature_names_out()):
    if coefficients[i] > 0:
        print(f"{word}: {coefficients[i]:.2f}")
    else:
        break

positive_features = np.argsort(coefficients)[-10:]
print("\nTop 10 positive features (spam):")
for i in positive_features:
    print(f"{vectorizer.get_feature_names_out()[i]}: {coefficients[i]:.2f}")

negative_features = np.argsort(coefficients)[:10]
print("\nTop 10 negative features (ham):")
for i in negative_features:
    print(f"{vectorizer.get_feature_names_out()[i]}: {coefficients[i]:.2f}")
